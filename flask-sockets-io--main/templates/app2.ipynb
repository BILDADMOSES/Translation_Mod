{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rogendo/sw-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Rogendo/sw-en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rogendo/en-sw\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Rogendo/en-sw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated Swahili text: Ninaitwa Emily\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "def translate_text(french_text: str, tokenizer, model) -> str:\n",
    "    # Tokenize the French text\n",
    "    inputs = tokenizer(french_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Generate the English translation\n",
    "    outputs = model.generate(**inputs)\n",
    "    # Decode the English translation\n",
    "    english_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return english_text\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Save only the model name or any relevant information\n",
    "    model_info = {\"model_name\": \"Rogendo/en-sw\"}\n",
    "    \n",
    "    with open('Eng_to_Swa_Translator_info.pkl', 'wb') as info_file:\n",
    "        pickle.dump(model_info, info_file)\n",
    "    \n",
    "    # Later, when you want to use the translation functionality:\n",
    "    with open('Eng_to_Swa_Translator_info.pkl', 'rb') as info_file:\n",
    "        loaded_model_info = pickle.load(info_file)\n",
    "    \n",
    "    loaded_tokenizer = AutoTokenizer.from_pretrained(loaded_model_info[\"model_name\"])\n",
    "    loaded_model = AutoModelForSeq2SeqLM.from_pretrained(loaded_model_info[\"model_name\"])\n",
    "    \n",
    "    # Now you can use the translate_text function with the loaded tokenizer and model\n",
    "    translated_text = translate_text(\"Hello\", loaded_tokenizer, loaded_model)\n",
    "    print(\"Translated Swahili text:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language predictions saved to language_predictions.pkl\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "text = [\n",
    "    \"Brevity is the soul of wit.\",\n",
    "    \"Upendo, ch'a nullo napenda kupenda, kusamehe.\"\n",
    "]\n",
    "\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt)\n",
    "\n",
    "inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "preds = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# Map raw predictions to languages\n",
    "id2lang = model.config.id2label\n",
    "vals, idxs = torch.max(preds, dim=1)\n",
    "lang_predictions = {id2lang[k.item()]: v.item() for k, v in zip(idxs, vals)}\n",
    "\n",
    "# Save the language predictions as a .pkl file\n",
    "output_file = \"language_predictions.pkl\"\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(lang_predictions, f)\n",
    "\n",
    "print(f\"Language predictions saved to {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, session, redirect, url_for\n",
    "from flask_socketio import join_room, leave_room, send, SocketIO\n",
    "import random\n",
    "from string import ascii_uppercase\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config[\"SECRET_KEY\"] = \"hjhjsdahhds\"\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "rooms = {}\n",
    "\n",
    "# Load the Swahili-to-English model information\n",
    "with open('Swa_to_Eng_Translator_info.pkl', 'rb') as info_file:\n",
    "    swa_to_eng_model_info = pickle.load(info_file)\n",
    "\n",
    "# Load the Swahili-to-English tokenizer and model\n",
    "swa_to_eng_tokenizer = AutoTokenizer.from_pretrained(swa_to_eng_model_info[\"model_name\"])\n",
    "swa_to_eng_model = AutoModelForSeq2SeqLM.from_pretrained(swa_to_eng_model_info[\"model_name\"])\n",
    "\n",
    "def translate_text(tokenizer, model, text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Generate the translation\n",
    "    outputs = model.generate(**inputs)\n",
    "    # Decode the translation\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def generate_unique_code(length):\n",
    "    while True:\n",
    "        code = \"\".join(random.choice(ascii_uppercase) for _ in range(length))\n",
    "        if code not in rooms:\n",
    "            break\n",
    "    return code\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/home\", methods=[\"POST\", \"GET\"])\n",
    "def home():\n",
    "    session.clear()\n",
    "    if request.method == \"POST\":\n",
    "        name = request.form.get(\"name\")\n",
    "        code = request.form.get(\"code\")\n",
    "        join = request.form.get(\"join\", False)\n",
    "        create = request.form.get(\"create\", False)\n",
    "\n",
    "        if not name:\n",
    "            return render_template(\"home.html\", error=\"Please enter a name.\", code=code, name=name)\n",
    "\n",
    "        if join != False and not code:\n",
    "            return render_template(\"home.html\", error=\"Please enter a room code.\", code=code, name=name)\n",
    "\n",
    "        room = code\n",
    "        if create != False:\n",
    "            room = generate_unique_code(4)\n",
    "            rooms[room] = {\"members\": 0, \"messages\": []}\n",
    "        elif code not in rooms:\n",
    "            return render_template(\"home.html\", error=\"Room does not exist.\", code=code, name=name)\n",
    "\n",
    "        session[\"room\"] = room\n",
    "        session[\"name\"] = name\n",
    "        return redirect(url_for(\"room\"))\n",
    "\n",
    "    return render_template(\"home.html\")\n",
    "\n",
    "@app.route(\"/room\")\n",
    "def room():\n",
    "    room = session.get(\"room\")\n",
    "    if room is None or session.get(\"name\") is None or room not in rooms:\n",
    "        return redirect(url_for(\"home\"))\n",
    "\n",
    "    return render_template(\"room.html\", code=room, messages=rooms[room][\"messages\"])\n",
    "\n",
    "@socketio.on(\"message\")\n",
    "def message(data):\n",
    "    room = session.get(\"room\")\n",
    "    if room not in rooms:\n",
    "        return\n",
    "    \n",
    "    message_text = data[\"data\"]\n",
    "\n",
    "    # Translate the message from Swahili to English\n",
    "    translated_message = translate_text(swa_to_eng_tokenizer, swa_to_eng_model, message_text)\n",
    "\n",
    "    content_sender = {\n",
    "        \"name\": session.get(\"name\"),\n",
    "        \"message\": message_text\n",
    "    }\n",
    "\n",
    "    content_receiver = {\n",
    "        \"name\": session.get(\"name\"),\n",
    "        \"message\": translated_message\n",
    "    }\n",
    "    \n",
    "    # Send the original message to the sender and the translated message to others in the room\n",
    "    send(content_sender, to=request.sid)\n",
    "    send(content_receiver, to=room, skip_sid=request.sid)\n",
    "    \n",
    "    rooms[room][\"messages\"].append(content_receiver)\n",
    "    print(f\"{session.get('name')} said: {message_text}\")\n",
    "\n",
    "\n",
    "@socketio.on(\"connect\")\n",
    "def connect(auth):\n",
    "    room = session.get(\"room\")\n",
    "    name = session.get(\"name\")\n",
    "    if not room or not name:\n",
    "        return\n",
    "    if room not in rooms:\n",
    "        leave_room(room)\n",
    "        return\n",
    "\n",
    "    join_room(room)\n",
    "    send({\"name\": name, \"message\": \"has entered the room\"}, to=room)\n",
    "    rooms[room][\"members\"] += 1\n",
    "    print(f\"{name} joined room {room}\")\n",
    "\n",
    "@socketio.on(\"disconnect\")\n",
    "def disconnect():\n",
    "    room = session.get(\"room\")\n",
    "    name = session.get(\"name\")\n",
    "    leave_room(room)\n",
    "\n",
    "    if room in rooms:\n",
    "        rooms[room][\"members\"] -= 1\n",
    "        if rooms[room][\"members\"] <= 0:\n",
    "            del rooms[room]\n",
    "\n",
    "    send({\"name\": name, \"message\": \"has left the room\"}, to=room)\n",
    "    print(f\"{name} has left the room {room}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, session, redirect, url_for\n",
    "from flask_socketio import join_room, leave_room, send, SocketIO\n",
    "import random\n",
    "from string import ascii_uppercase\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config[\"SECRET_KEY\"] = \"hjhjsdahhds\"\n",
    "socketio = SocketIO(app)\n",
    "\n",
    "rooms = {}\n",
    "\n",
    "# Load the language detection model\n",
    "language_model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "language_tokenizer = AutoTokenizer.from_pretrained(language_model_ckpt)\n",
    "language_model = AutoModelForSequenceClassification.from_pretrained(language_model_ckpt)\n",
    "\n",
    "# Load the English-to-Swahili translation model\n",
    "eng_to_swa_model_info = pickle.load(open('Eng_to_Swa_Translator_info.pkl', 'rb'))\n",
    "eng_to_swa_tokenizer = AutoTokenizer.from_pretrained(eng_to_swa_model_info[\"model_name\"])\n",
    "eng_to_swa_model = AutoModelForSeq2SeqLM.from_pretrained(eng_to_swa_model_info[\"model_name\"])\n",
    "\n",
    "# Load the Swahili-to-English translation model\n",
    "swa_to_eng_model_info = pickle.load(open('Swa_to_Eng_Translator_info.pkl', 'rb'))\n",
    "swa_to_eng_tokenizer = AutoTokenizer.from_pretrained(swa_to_eng_model_info[\"model_name\"])\n",
    "swa_to_eng_model = AutoModelForSeq2SeqLM.from_pretrained(swa_to_eng_model_info[\"model_name\"])\n",
    "\n",
    "def detect_language(text):\n",
    "    inputs = language_tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = language_model(**inputs).logits\n",
    "    preds = torch.softmax(logits, dim=-1)\n",
    "    id2lang = language_model.config.id2label\n",
    "    vals, idxs = torch.max(preds, dim=1)\n",
    "    return id2lang[idxs[0].item()]\n",
    "\n",
    "def translate_text(tokenizer, model, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def generate_unique_code(length):\n",
    "    while True:\n",
    "        code = \"\".join(random.choice(ascii_uppercase) for _ in range(length))\n",
    "        if code not in rooms:\n",
    "            break\n",
    "    return code\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/home\", methods=[\"POST\", \"GET\"])\n",
    "def home():\n",
    "    session.clear()\n",
    "    if request.method == \"POST\":\n",
    "        name = request.form.get(\"name\")\n",
    "        code = request.form.get(\"code\")\n",
    "        join = request.form.get(\"join\", False)\n",
    "        create = request.form.get(\"create\", False)\n",
    "\n",
    "        if not name:\n",
    "            return render_template(\"home.html\", error=\"Please enter a name.\", code=code, name=name)\n",
    "\n",
    "        if join != False and not code:\n",
    "            return render_template(\"home.html\", error=\"Please enter a room code.\", code=code, name=name)\n",
    "\n",
    "        room = code\n",
    "        if create != False:\n",
    "            room = generate_unique_code(4)\n",
    "            rooms[room] = {\"members\": 0, \"messages\": []}\n",
    "        elif code not in rooms:\n",
    "            return render_template(\"home.html\", error=\"Room does not exist.\", code=code, name=name)\n",
    "\n",
    "        session[\"room\"] = room\n",
    "        session[\"name\"] = name\n",
    "        return redirect(url_for(\"room\"))\n",
    "\n",
    "    return render_template(\"home.html\")\n",
    "\n",
    "@app.route(\"/room\")\n",
    "def room():\n",
    "    room = session.get(\"room\")\n",
    "    if room is None or session.get(\"name\") is None or room not in rooms:\n",
    "        return redirect(url_for(\"home\"))\n",
    "\n",
    "    return render_template(\"room.html\", code=room, messages=rooms[room][\"messages\"])\n",
    "\n",
    "@socketio.on(\"message\")\n",
    "def message(data):\n",
    "    room = session.get(\"room\")\n",
    "    if room not in rooms:\n",
    "        return\n",
    "    \n",
    "    message_text = data[\"data\"]\n",
    "\n",
    "    # Detect language\n",
    "    language = detect_language(message_text)\n",
    "\n",
    "    # Translate based on detected language\n",
    "    if language == \"en\":\n",
    "        translated_message = translate_text(eng_to_swa_tokenizer, eng_to_swa_model, message_text)\n",
    "    elif language == \"sw\":\n",
    "        translated_message = translate_text(swa_to_eng_tokenizer, swa_to_eng_model, message_text)\n",
    "    else:\n",
    "        translated_message = \"Language not supported\"\n",
    "\n",
    "    content = {\n",
    "        \"name\": session.get(\"name\"),\n",
    "        \"message\": translated_message\n",
    "    }\n",
    "    \n",
    "    send(content, to=room)\n",
    "    rooms[room][\"messages\"].append(content)\n",
    "    print(f\"{session.get('name')} said: {message_text}\")\n",
    "\n",
    "@socketio.on(\"connect\")\n",
    "def connect(auth):\n",
    "    room = session.get(\"room\")\n",
    "    name = session.get(\"name\")\n",
    "    if not room or not name:\n",
    "        return\n",
    "    if room not in rooms:\n",
    "        leave_room(room)\n",
    "        return\n",
    "\n",
    "    join_room(room)\n",
    "    send({\"name\": name, \"message\": \"has entered the room\"}, to=room)\n",
    "    rooms[room][\"members\"] += 1\n",
    "    print(f\"{name} joined room {room}\")\n",
    "\n",
    "@socketio.on(\"disconnect\")\n",
    "def disconnect():\n",
    "    room = session.get(\"room\")\n",
    "    name = session.get(\"name\")\n",
    "    leave_room(room)\n",
    "\n",
    "    if room in rooms:\n",
    "        rooms[room][\"members\"] -= 1\n",
    "        if rooms[room][\"members\"] <= 0:\n",
    "            del rooms[room]\n",
    "\n",
    "    send({\"name\": name, \"message\": \"has left the room\"}, to=room)\n",
    "    print(f\"{name} has left the room {room}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    socketio.run(app, debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
