{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e19cca4",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "- pandas\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498f79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9021e2c",
   "metadata": {},
   "source": [
    "## Using pandas library to retrieve the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aebce4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Eng-Fre.csv\"\n",
    "df = pd.read_csv(file, encoding= 'utf-8')\n",
    "df = df.replace('�','',regex = True)\n",
    "#df.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\Eng-Fre2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42883f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>?a alors?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
       "      <td>? L'?conomie en partant du haut vers le bas, ?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
       "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>Death is something that we're often discourage...</td>\n",
       "      <td>La mort est une chose qu'on nous d?courage sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>Since there are usually multiple websites on a...</td>\n",
       "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>If someone who doesn't know your background sa...</td>\n",
       "      <td>Si quelqu'un qui ne conna?t pas vos ant?c?dent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English words/sentences  \\\n",
       "0                                                     Hi.   \n",
       "1                                                    Run!   \n",
       "2                                                    Run!   \n",
       "3                                                    Who?   \n",
       "4                                                    Wow!   \n",
       "...                                                   ...   \n",
       "175616  Top-down economics never works, said Obama. \"T...   \n",
       "175617  A carbon footprint is the amount of carbon dio...   \n",
       "175618  Death is something that we're often discourage...   \n",
       "175619  Since there are usually multiple websites on a...   \n",
       "175620  If someone who doesn't know your background sa...   \n",
       "\n",
       "                                   French words/sentences  \n",
       "0                                                  Salut!  \n",
       "1                                                 Cours?!  \n",
       "2                                                Courez?!  \n",
       "3                                                   Qui ?  \n",
       "4                                              ?a alors?!  \n",
       "...                                                   ...  \n",
       "175616  ? L'?conomie en partant du haut vers le bas, ?...  \n",
       "175617  Une empreinte carbone est la somme de pollutio...  \n",
       "175618  La mort est une chose qu'on nous d?courage sou...  \n",
       "175619  Puisqu'il y a de multiples sites web sur chaqu...  \n",
       "175620  Si quelqu'un qui ne conna?t pas vos ant?c?dent...  \n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "529d4684",
   "metadata": {},
   "source": [
    "## Checking for any null values\n",
    "Checking for missing values: \n",
    "- **df.isnull()** or **df.isna()** - will return true if null\n",
    "- **df.notnull()** - will return true false if null\n",
    "\n",
    "Handling missing values:\n",
    "1)   Removing rows or columns with missing values: **df.dropna()**\n",
    "2)   Interpolating missing values: **df.interpolate()**\n",
    "3)   Imputing missing values: You can use **df.fillna(value)** to fill missing values with a specific value, or use more advanced techniques like mean, median, or machine learning algorithms for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b932e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    0\n",
       "French words/sentences     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a20e2116",
   "metadata": {},
   "source": [
    "## Checking for unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b57fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289032"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faf9a543",
   "metadata": {},
   "source": [
    "## Checking the number of rows\n",
    "Shape function will return a tuple consisting of 2 indices, 1st (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54508b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6b6987",
   "metadata": {},
   "source": [
    "## Checking for number of records\n",
    "We also could use this to see the number of records in every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1808bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    175621\n",
       "French words/sentences     175621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2eb088",
   "metadata": {},
   "source": [
    "## Checking for the data types of values within the dataframe\n",
    "We could use **astype(dtype)** to change the data type of records e.g. df.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f17c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    object\n",
       "French words/sentences     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cae2dcc",
   "metadata": {},
   "source": [
    "## Checking for number of duplicates\n",
    "- Detecting duplicates: **df.duplicated()** to check for duplicate rows.\n",
    "- Removing duplicates: **df.drop_duplicates()** to remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e68e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52521"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"English words/sentences\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8741de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English words/sentences  French words/sentences\n",
       "0                         False                   False\n",
       "1                         False                   False\n",
       "2                         False                   False\n",
       "3                         False                   False\n",
       "4                         False                   False\n",
       "...                         ...                     ...\n",
       "175616                    False                   False\n",
       "175617                    False                   False\n",
       "175618                    False                   False\n",
       "175619                    False                   False\n",
       "175620                    False                   False\n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71f6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng, Fre = df[\"English words/sentences\"], df[\"French words/sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c855805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Printing out a collection of punctuation marks, ASCII characters\n",
    "print(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2cb05f5",
   "metadata": {},
   "source": [
    "## Removing the Punctuation Marks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31237e78",
   "metadata": {},
   "source": [
    "Initially I did this but then realized that I wasn't really using the fully capabilities of the <span style = \"color:red\">if statement</span>. You notice that I am instead using the else statement to append the letters to my **col** list.\n",
    "\n",
    "    def remove_punc(column):\n",
    "        new_column = []\n",
    "        for word in column:\n",
    "            col = [] \n",
    "            for letter in word:\n",
    "                if letter in string.punctuation:\n",
    "                    letter = letter.replace(letter,'')\n",
    "                else:\n",
    "                    col.append(letter) #list for individual letters now without punctuation mark\n",
    "                new_word = \"\".join(col)\n",
    "            new_column.append(new_word)    \n",
    "        return new_column\n",
    "\n",
    "Instead I used <span style = \"color:blue\">not in</span> which was more effective and cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7558d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(column):\n",
    "    new_column = []\n",
    "    for word in column:\n",
    "        col = []\n",
    "        for letter in word:\n",
    "            if letter not in string.punctuation:\n",
    "                col.append(letter) #list for individual letters now without punctuation mark\n",
    "            new_word = \"\".join(col)\n",
    "        new_column.append(new_word)    \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54dde395",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Eng = remove_punc(Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf3087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Fre = remove_punc(Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f110edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3670efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Eng = [nltk.word_tokenize(word) for word in No_Punc_Eng]\n",
    "len(tokenized_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b794a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Fre = [nltk.word_tokenize(word) for word in No_Punc_Fre]\n",
    "len(tokenized_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34d8dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68ab5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying if that we have English and French Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aebf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Eng = stopwords.words('english') #179 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e76682",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Fre = stopwords.words('french') #157 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6163df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Eng = []\n",
    "for word in tokenized_Eng:\n",
    "    if word not in stop_Eng:\n",
    "        No_Stop_Eng.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bfd1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57d5ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Fre = []\n",
    "for word in tokenized_Fre:\n",
    "    if word not in stop_Fre:\n",
    "        No_Stop_Fre.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "558ced41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5df7dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Fre = []\n",
    "for words in No_Stop_Fre:\n",
    "    for word in words:\n",
    "        lower_Fre.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcb6b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Eng = []\n",
    "for words in No_Stop_Eng:\n",
    "    for word in words:\n",
    "        lower_Eng.append(word.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cf29fa",
   "metadata": {},
   "source": [
    "I will opt for lemmatization and not stemming as I did before:\n",
    "\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Stem--\"))\n",
    "    for word in lower_Eng:\n",
    "        print(\"   {0:25}  {1:25} \".format(word,ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01724e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all') - Every Package is Up-to-date for my Ellie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7510e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22ff8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ae39705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "'''print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Lemma--\"))\n",
    "for word in lower_Fre:\n",
    "    print(\"   {0:25}  {1:25} \".format(word, wnl.lemmatize(word, pos='v')))'''\n",
    "    \n",
    "lemm_Eng = [wnl.lemmatize(word, pos='v') for word in lower_Eng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1feb7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load()\n",
    "#for word in lower_Fre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b10dd70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for sent in col.sents:\\n    print(sent.text)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"This is an example sentence.\"\n",
    "#col = list(nlp.pipe(lower_Eng))\n",
    "\n",
    "\n",
    "\n",
    "#docs = [nlp(text) for text in lower_Eng]\n",
    "\n",
    "# Accessing sentence-level information\n",
    "'''for sent in col.sents:\n",
    "    print(sent.text)'''\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04edf951",
   "metadata": {},
   "source": [
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e682391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for text in lower_Fre:\\n    doc = nlp(text)\\n    for word in doc:\\n        print(word, word.lemma_)'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "lemm_Fre = []\n",
    "Fre.duplicated()\n",
    "'''for text in lower_Fre:\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        print(word, word.lemma_)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f4ec60",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 70:30 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng_train, Eng_test, Fre_train, Fre_test = train_test_split(Eng, Fre, test_size= .33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
