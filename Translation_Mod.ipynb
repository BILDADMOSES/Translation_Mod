{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403f5b87",
   "metadata": {},
   "source": [
    "## Brief description of the data set and a summary of its attributes\n",
    "My data set is made up of two columns: English words/sentences and French words/sentences.\n",
    "\n",
    "It contains 175622 rows, of which there wasn’t any null values.\n",
    "\n",
    "I pulled the data set from Kaggle as I needed data containing proper and correct translation of both languages. I am also fluent only in one of the languages, English thus it provided me with a ready made translation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e19cca4",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "- pandas\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "498f79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9021e2c",
   "metadata": {},
   "source": [
    "## Using pandas library to retrieve the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aebce4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Eng-Fre.csv\"\n",
    "df = pd.read_csv(file, encoding= 'utf-8')\n",
    "df = df.replace('�','',regex = True)\n",
    "#df.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\Eng-Fre2.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9332c7f",
   "metadata": {},
   "source": [
    "## Printing out the first 5 rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42883f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>?a alors?!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours?!\n",
       "2                    Run!               Courez?!\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             ?a alors?!"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "529d4684",
   "metadata": {},
   "source": [
    "## Checking for any null values\n",
    "Checking for missing values: \n",
    "- **df.isnull()** or **df.isna()** - will return true if null\n",
    "- **df.notnull()** - will return true false if null\n",
    "\n",
    "Handling missing values:\n",
    "1)   Removing rows or columns with missing values: **df.dropna()**\n",
    "2)   Interpolating missing values: **df.interpolate()**\n",
    "3)   Imputing missing values: You can use **df.fillna(value)** to fill missing values with a specific value, or use more advanced techniques like mean, median, or machine learning algorithms for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b932e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    0\n",
       "French words/sentences     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a20e2116",
   "metadata": {},
   "source": [
    "## Checking for unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b57fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289032"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faf9a543",
   "metadata": {},
   "source": [
    "## Checking the number of rows\n",
    "Shape function will return a tuple consisting of 2 indices, 1st (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "54508b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6b6987",
   "metadata": {},
   "source": [
    "## Checking for number of records\n",
    "We also could use this to see the number of records in every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1808bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    175621\n",
       "French words/sentences     175621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2eb088",
   "metadata": {},
   "source": [
    "## Checking for the data types of values within the dataframe\n",
    "We could use **astype(dtype)** to change the data type of records e.g. df.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f17c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    object\n",
       "French words/sentences     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cae2dcc",
   "metadata": {},
   "source": [
    "## Checking for number of duplicates\n",
    "- Detecting duplicates: **df.duplicated()** to check for duplicate rows.\n",
    "- Removing duplicates: **df.drop_duplicates()** to remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e68e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1dd6993",
   "metadata": {},
   "source": [
    "## Printing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0d91cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Stand back!</td>\n",
       "      <td>Reculez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>It's not funny.</td>\n",
       "      <td>Ce n'est pas dr?le !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65263</th>\n",
       "      <td>What time will you leave?</td>\n",
       "      <td>? quelle heure pars-tu??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100309</th>\n",
       "      <td>What's the weather like today?</td>\n",
       "      <td>Quel temps fait-il aujourd'hui??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147869</th>\n",
       "      <td>Medical marijuana is legal in this state.</td>\n",
       "      <td>La marijuana th?rapeutique est l?gale dans cet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          English words/sentences  \\\n",
       "1621                                  Stand back!   \n",
       "8626                              It's not funny.   \n",
       "65263                   What time will you leave?   \n",
       "100309             What's the weather like today?   \n",
       "147869  Medical marijuana is legal in this state.   \n",
       "\n",
       "                                   French words/sentences  \n",
       "1621                                            Reculez !  \n",
       "8626                                 Ce n'est pas dr?le !  \n",
       "65263                            ? quelle heure pars-tu??  \n",
       "100309                   Quel temps fait-il aujourd'hui??  \n",
       "147869  La marijuana th?rapeutique est l?gale dans cet...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8741de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English words/sentences  French words/sentences\n",
       "0                         False                   False\n",
       "1                         False                   False\n",
       "2                         False                   False\n",
       "3                         False                   False\n",
       "4                         False                   False\n",
       "...                         ...                     ...\n",
       "175616                    False                   False\n",
       "175617                    False                   False\n",
       "175618                    False                   False\n",
       "175619                    False                   False\n",
       "175620                    False                   False\n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f71f6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng, Fre = df[\"English words/sentences\"], df[\"French words/sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5c855805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Printing out a collection of punctuation marks, ASCII characters\n",
    "print(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2cb05f5",
   "metadata": {},
   "source": [
    "## Removing the Punctuation Marks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31237e78",
   "metadata": {},
   "source": [
    "Initially I did this but then realized that I wasn't really using the fully capabilities of the <span style = \"color:red\">if statement</span>. You notice that I am instead using the else statement to append the letters to my **col** list.\n",
    "\n",
    "    def remove_punc(column):\n",
    "        new_column = []\n",
    "        for word in column:\n",
    "            col = [] \n",
    "            for letter in word:\n",
    "                if letter in string.punctuation:\n",
    "                    letter = letter.replace(letter,'')\n",
    "                else:\n",
    "                    col.append(letter) #list for individual letters now without punctuation mark\n",
    "                new_word = \"\".join(col)\n",
    "            new_column.append(new_word)    \n",
    "        return new_column\n",
    "\n",
    "Instead I used <span style = \"color:blue\">not in</span> which was more effective and cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7558d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(column):\n",
    "    new_column = []\n",
    "    for word in column:\n",
    "        col = []\n",
    "        for letter in word:\n",
    "            if letter not in string.punctuation:\n",
    "                col.append(letter) #list for individual letters now without punctuation mark\n",
    "            new_word = \"\".join(col)\n",
    "        new_column.append(new_word)    \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54dde395",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Eng = remove_punc(Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cf3087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Fre = remove_punc(Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f110edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3670efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Eng = [nltk.word_tokenize(word) for word in No_Punc_Eng]\n",
    "len(tokenized_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b794a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Fre = [nltk.sent_tokenize(word) for word in No_Punc_Fre]\n",
    "len(tokenized_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34d8dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68ab5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying if that we have English and French Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0aebf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Eng = stopwords.words('english') #179 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a5e76682",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Fre = stopwords.words('french') #157 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6163df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Eng = []\n",
    "for word in tokenized_Eng:\n",
    "    if word not in stop_Eng:\n",
    "        No_Stop_Eng.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0bfd1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57d5ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Fre = []\n",
    "for word in tokenized_Fre:\n",
    "    if word not in stop_Fre:\n",
    "        No_Stop_Fre.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "558ced41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5df7dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Fre = []\n",
    "for words in No_Stop_Fre:\n",
    "    for word in words:\n",
    "        lower_Fre.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fcb6b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Eng = []\n",
    "for words in No_Stop_Eng:\n",
    "    for word in words:\n",
    "        lower_Eng.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fba9b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "df2 = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "df.to_parquet(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.parquet\")\n",
    "df2.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "efc6b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "French = pd.read_parquet(\"French.parquet\")\n",
    "len(French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "35790dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#French2 = pd.read_csv(\"French.csv\", usecols=lambda col: col != 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "85ea6fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "FrenchPar = dd.read_parquet(\"French.parquet\")\n",
    "len(FrenchPar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "05a84bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar = FrenchPar.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f59b26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar.to_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7e4d34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(lower_Eng,columns= [\"English Words\"])\n",
    "df3.to_parquet(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\English.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c4424c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082311</th>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082312</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082313</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082314</th>\n",
       "      <td>native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082315</th>\n",
       "      <td>speaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082316 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English Words\n",
       "0                  hi\n",
       "1                 run\n",
       "2                 run\n",
       "3                 who\n",
       "4                 wow\n",
       "...               ...\n",
       "1082311         sound\n",
       "1082312          like\n",
       "1082313             a\n",
       "1082314        native\n",
       "1082315       speaker\n",
       "\n",
       "[1082316 rows x 1 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnglishPar = pd.read_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\English.parquet\")\n",
    "EnglishPar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "de1fdc12",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'npartitions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22136\\2803937488.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEnglishPar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnpartitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Bildad Otieno\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5898\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5899\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5900\u001b[0m         ):\n\u001b[0;32m   5901\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'npartitions'"
     ]
    }
   ],
   "source": [
    "EnglishPar.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f2707308",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'repartition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22136\\2625817941.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEnglishPar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnglishPar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Bildad Otieno\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5898\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5899\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5900\u001b[0m         ):\n\u001b[0;32m   5901\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'repartition'"
     ]
    }
   ],
   "source": [
    "EnglishPar = EnglishPar.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3d7f310a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082311</th>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082312</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082313</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082314</th>\n",
       "      <td>native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082315</th>\n",
       "      <td>speaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1082316 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English Words\n",
       "0                  hi\n",
       "1                 run\n",
       "2                 run\n",
       "3                 who\n",
       "4                 wow\n",
       "...               ...\n",
       "1082311         sound\n",
       "1082312          like\n",
       "1082313             a\n",
       "1082314        native\n",
       "1082315       speaker\n",
       "\n",
       "[1082316 rows x 1 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnglishPar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cf29fa",
   "metadata": {},
   "source": [
    "I will opt for lemmatization and not stemming as I did before:\n",
    "\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Stem--\"))\n",
    "    for word in lower_Eng:\n",
    "        print(\"   {0:25}  {1:25} \".format(word,ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "01724e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all') - Every Package is Up-to-date for my Ellie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7510e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "22ff8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8ae39705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "'''print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Lemma--\"))\n",
    "for word in lower_Fre:\n",
    "    print(\"   {0:25}  {1:25} \".format(word, wnl.lemmatize(word, pos='v')))'''\n",
    "    \n",
    "lemm_Eng = [wnl.lemmatize(word, pos='v') for word in lower_Eng]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04edf951",
   "metadata": {},
   "source": [
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e682391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "Part0 = dd.read_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\\part.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7cd9da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FreWord = []\n",
    "for word in FrenchPar.to_delayed():\n",
    "    FreWord.append(word.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  French Words \n",
      " 0                        salut \n",
      " 1                        cours \n",
      " 2                       courir \n",
      " 3                          qui \n",
      " 4                      avoir alors \n",
      " ...                        ... \n",
      " 8776   puisje me joindre   vous \n",
      " 8777   puisje vous accompagner \n",
      " 8778     puisje vous embrasser \n",
      " 8779       puisje masseoir ici \n",
      " 8780      puisje utiliser ceci \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                      French Words \n",
      " 8781    le homme être un idiot \n",
      " 8782       le homme être simple \n",
      " 8783               il en falloir plus \n",
      " 8784        motu et bouche coudre \n",
      " 8785           mon voiture être sale \n",
      " ...                            ... \n",
      " 17557       vous nte pas chanteur \n",
      " 17558      vous nte pas chanteur \n",
      " 17559          tu nes pas chanteur \n",
      " 17560         tu nes pas chanteur \n",
      " 17561              tu nes pas seul \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                   French Words \n",
      " 17562          tu ner pas seul \n",
      " 17563        vous nte pas seul \n",
      " 17564       vous nte pas seul \n",
      " 17565      vous nte pas seul \n",
      " 17566       vous nte pas seul \n",
      " ...                         ... \n",
      " 26338    tom avoir un mauvais rhume \n",
      " 26339         tom avoir un gros nez \n",
      " 26340   tom avoir un voiture bleu \n",
      " 26341   tom avoir le gueule de bois \n",
      " 26342       tom avoir un moustache \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                           French Words \n",
      " 26343                           tom avoir le cheveu noir \n",
      " 26344                           tom avoir le cheveu brun \n",
      " 26345                                     tom ton choisir \n",
      " 26346                                 tom vous avoir choisir \n",
      " 26347                            tom avoir perdre le pdale \n",
      " ...                                                 ... \n",
      " 35119               jai entendre mon pantalon se dchirer \n",
      " 35120                           jai entendre le question \n",
      " 35121   jai entendre dire que vous vous en tiez bien tir \n",
      " 35122         jai entendre dire que tu ten taire bien tir \n",
      " 35123                            jai engag un assistant \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                        French Words \n",
      " 35124     il mest venir un bon ide \n",
      " 35125    jespre que ce nest pas vrai \n",
      " 35126     jespre que cest un blague \n",
      " 35127       jespre quils mont apprci \n",
      " 35128    jespre quel mont apprcie \n",
      " ...                              ... \n",
      " 43900     le guerre nest pas terminer \n",
      " 43901                  leau être tide \n",
      " 43902             le temps taire idal \n",
      " 43903     le baleine être un mammifre \n",
      " 43904   le vent souffler tout le jour \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                  French Words \n",
      " 43905         le vent avoir souffl tout le journe \n",
      " 43906              le fentre taient ouvrir \n",
      " 43907               le femme être au travail \n",
      " 43908                   le femme travailler \n",
      " 43909                         le monde avoir chang \n",
      " ...                                        ... \n",
      " 52681         être plus gentil avec votre sur \n",
      " 52682       être plus gentil avec votre sur \n",
      " 52683      être plus gentil avec votre sur \n",
      " 52684                  bel journe nestce pas \n",
      " 52685   il faire un temps magnifique nestce pas \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                              French Words \n",
      " 52686         magnifique journe nestce pas \n",
      " 52687      le beaut nest que superficiel \n",
      " 52688      attention à chute de pierre \n",
      " 52689      le chat noir porter malheur \n",
      " 52690                   le noir te aller bien \n",
      " ...                                    ... \n",
      " 61462          je savoir que tom avoir t horrifi \n",
      " 61463   je savoir que tom ne plaisanter pas \n",
      " 61464     je savoir que tom nabandonnerer pas \n",
      " 61465   je être au courant pour ton cancer \n",
      " 61466           je connaître le deux fille \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                     French Words \n",
      " 61467                  je savoir prcisment qui cest \n",
      " 61468           je savoir prcisment de qui il sagit \n",
      " 61469                 je savoir que cest impossible \n",
      " 61470                je savoir que ce nest quun rve \n",
      " 61471           je savoir que cest seulement un rve \n",
      " ...                                           ... \n",
      " 70243             cest difficile de te surprendre \n",
      " 70244                 tu être difficile   surprendre \n",
      " 70245              cest plus dur que avoir nen avoir lair \n",
      " 70246                  cest incroyable nestce pas \n",
      " 70247   cest juste le manire dont celer fonctionner \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                        French Words \n",
      " 70248   cest juste ainsi que le chose fonctionner \n",
      " 70249                        cest plutt embarrassant \n",
      " 70250              il être plus tard que tu ne pense \n",
      " 70251                    il être presque trois heure \n",
      " 70252                         avoir ne mest jamais arriv \n",
      " ...                                              ... \n",
      " 79024                       tom avoir un accent amricain \n",
      " 79025           tom avoir faire un rserve de nourriture \n",
      " 79026             tom na pas dire un mot de le journe \n",
      " 79027        tom être rest silencieux tout le journe \n",
      " 79028                  tom avoir t silencieux aujourdhui \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                             French Words \n",
      " 79029        tom na rien dire de le journe \n",
      " 79030               tom avoir t prendre en otage \n",
      " 79031                  tom avoir t trs gnreux \n",
      " 79032        tom avoir un ide constructif \n",
      " 79033        tom avoir dcid de faire le deux \n",
      " ...                                   ... \n",
      " 87805    sontils japoner ou bien chinois \n",
      " 87806   sontelle japonais ou chinois \n",
      " 87807        estce quils rentrer ce soir \n",
      " 87808                  vontils arrter tom \n",
      " 87809                vontelle arrter tom \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                French Words \n",
      " 87810                il vendre son maison \n",
      " 87811         sommesnou seul dans luniver \n",
      " 87812        sommesnou seul dans luniver \n",
      " 87813                   astu peur de lavenir \n",
      " 87814          tesvous tout compltement fou \n",
      " ...                                      ... \n",
      " 96586   jer quelque chose quil me falloir faire \n",
      " 96587                 jai autre chose en tte \n",
      " 96588   jai galement quelque chose pour vous \n",
      " 96589    jai galement quelque chose pour toi \n",
      " 96590          il me reste trois page   lire \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                               French Words \n",
      " 96591      je devoir escalader ce montagne \n",
      " 96592         je devoir gravir ce montagne \n",
      " 96593        je devoir faire cuire le lgume \n",
      " 96594           je devoir cuisiner le lgume \n",
      " 96595              je devoir expliquer avoir   tom \n",
      " ...                                     ... \n",
      " 105367             le police mne son enqute \n",
      " 105368     le police na pas encore de piste \n",
      " 105369        le possibilit être infini \n",
      " 105370      le presse avoir confirm le rumeur \n",
      " 105371   le pression se faire sentir sur luire \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                    French Words \n",
      " 105372           le prix rester comme il être \n",
      " 105373          le problme nest pas encore rsolu \n",
      " 105374              le question être   qui le faire \n",
      " 105375          le lapin se cacher derrire larbre \n",
      " 105376         le lapin sest cach derrire larbre \n",
      " ...                                          ... \n",
      " 114148      comment savaistu quil en manquer un \n",
      " 114149    comment saviezvou quil en manquer un \n",
      " 114150        comment avezvous obtenir ce tableau \n",
      " 114151            comment astu obtenir ce tableau \n",
      " 114152   comment avezvous pass votre temps libre \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                         French Words \n",
      " 114153        comment comptentil que nous survivre \n",
      " 114154      comment comptentelle que nous survivre \n",
      " 114155      comment saistu quil ne sagit pas dun pige \n",
      " 114156   comment savezvous quil ne sagit pas dun pige \n",
      " 114157                   comment veuxtu que je payer avoir \n",
      " ...                                               ... \n",
      " 122929           quel genre de poisson être votre prfr \n",
      " 122930                     quand allezvous terminer avoir \n",
      " 122931                         quand vastu terminer avoir \n",
      " 122932                            quand te marierastu \n",
      " 122933                        quand vous marierezvous \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                       French Words \n",
      " 122934                  quand allezvous vous marier \n",
      " 122935                  quand estu revenu de boston \n",
      " 122936                quand tesvous rentr de boston \n",
      " 122937               quand tesvous rentrs de boston \n",
      " 122938                  quand estu rentrer de boston \n",
      " ...                                             ... \n",
      " 131710   nous avoir un travail important   faire ici \n",
      " 131711            avoir faire un heure quon attendre ici \n",
      " 131712         nous attendre ici depuis un heure \n",
      " 131713        nous avoir captur un de leur espion \n",
      " 131714             nous avoir quatre cours le matin \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                              French Words \n",
      " 131715               nous avoir le contrle de le situation \n",
      " 131716           nous avoir trois arbre dans notre jardin \n",
      " 131717            nous devoir faire attention   notre dpense \n",
      " 131718           il nous falloir faire attention   notre dpense \n",
      " 131719                         il nous falloir tre prts   tout \n",
      " ...                                                    ... \n",
      " 140491       je être responsable de cours de troisim anne \n",
      " 140492                        japprci beaucoup votre aide \n",
      " 140493                          japprci beaucoup ton aide \n",
      " 140494       je être vraiment dsol de tavoir faire attendre \n",
      " 140495   je être tellement dsol de vous avoir faire atte ... \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                              French Words \n",
      " 140496   je être tellement dsole de vous avoir faire att ... \n",
      " 140497    je être suppos aller   tokyo le semaine prochain \n",
      " 140498               je aller reprendre laffaire de mon pre \n",
      " 140499   je être reconnaître pour ce que tu essayer d ... \n",
      " 140500   je être reconnaissant pour ce que tu essayer ... \n",
      " ...                                                    ... \n",
      " 149272   le franai avoir beaucoup plus de voyelle que le ... \n",
      " 149273         le franai nest pas si difficile   apprendre \n",
      " 149274                     dsormais je aller tre l pour toi \n",
      " 149275                    dsormais je aller tre l pour vous \n",
      " 149276                   danne en anne le pollution empire \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                              French Words \n",
      " 149277        lessence schapper dune fissure dans le tube \n",
      " 149278      le gaz schapper dune fissure dans le conduite \n",
      " 149279          de faon gnral le amricain aimer le caf \n",
      " 149280   donneznou deux couteau et quatre fourchette ... \n",
      " 149281          tant donn son inexprience lui avoir bien faire \n",
      " ...                                                    ... \n",
      " 158053   officiellement il travailler pour nous en tant ... \n",
      " 158054   en entendre le mauvais nouveau lui clat ... \n",
      " 158055       lun de mon crivain prfrs être herman melvill \n",
      " 158056     on devoir traiter son enseignant avec respect \n",
      " 158057   seul un chameau pouvoir laisser un empreinte ... \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                              French Words \n",
      " 158058      notre appartement commencer   avoir de le gueule \n",
      " 158059      notre voisin avoir t obligs de vendre son maison \n",
      " 158060   notre quipe na pas atteindre ce anne le phas ... \n",
      " 158061   notre ultime but être dtablir le paix dans le m ... \n",
      " 158062   notre monde être seulement un minuscule partie ... \n",
      " ...                                                    ... \n",
      " 166834   tu nas pas   dire quoi que ce être que tu ne ve ... \n",
      " 166835       tu nes pas oblig den parler si tu ne vouloir pas \n",
      " 166836      tu nes pas obliger den parler si tu ne vouloir pas \n",
      " 166837   vous nte pas oblig den parler si vous ne voul ... \n",
      " 166838   vous nte pas obliger den parler si vous ne vou ... \n",
      "\n",
      " [ 8781 row x 1 column ]\n",
      "                                              French Words \n",
      " 166839   vous nte pas obligs den parler si vous ne vou ... \n",
      " 166840   vous nte pas obliger den parler si vous ne vo ... \n",
      " 166841   vous nte pas oblig den parler si vous ne le v ... \n",
      " 166842   vous nte pas obliger den parler si vous ne le ... \n",
      " 166843   vous nte pas obligs den parler si vous ne le ... \n",
      " ...                                                    ... \n",
      " 175616    lconomi en partir de haut vers le bas avoir ne ... \n",
      " 175617   un empreinte carbone être le somme de pollutio ... \n",
      " 175618   le mort être un chose quon nous dcourage souve ... \n",
      " 175619   puisquil y avoir de multiple site web sur chaque ... \n",
      " 175620   si quelquun qui ne connat pas votre antcdent di ... \n",
      "\n",
      " [ 8782 row x 1 column ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_col = []\n",
    "for text in FreWord:\n",
    "    doc = nlp(str(text))\n",
    "    col = []\n",
    "    for word in doc:\n",
    "        col.append(word.lemma_)\n",
    "    new_word = \" \".join(col)\n",
    "    new_col.append(new_word)\n",
    "    print(new_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e68012fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>courez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a alors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>lconomie en partant du haut vers le bas a ne ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>une empreinte carbone est la somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>la mort est une chose quon nous dcourage souve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>puisquil y a de multiples sites web sur chaque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>si quelquun qui ne connat pas vos antcdents di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             French Words\n",
       "0                                                   salut\n",
       "1                                                   cours\n",
       "2                                                  courez\n",
       "3                                                     qui\n",
       "4                                                 a alors\n",
       "...                                                   ...\n",
       "175616   lconomie en partant du haut vers le bas a ne ...\n",
       "175617  une empreinte carbone est la somme de pollutio...\n",
       "175618  la mort est une chose quon nous dcourage souve...\n",
       "175619  puisquil y a de multiples sites web sur chaque...\n",
       "175620  si quelquun qui ne connat pas vos antcdents di...\n",
       "\n",
       "[175621 rows x 1 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_pattern = r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\\part.*.parquet\"\n",
    "\n",
    "df4 = dd.read_parquet(file_pattern)\n",
    "\n",
    "merged_df4 = dd.concat([df4])\n",
    "\n",
    "merged_df4 = merged_df4.compute()\n",
    "merged_df4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f4ec60",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 70:30 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "791f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng_train, Eng_test, Fre_train, Fre_test = train_test_split(Eng, Fre, test_size= .33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
