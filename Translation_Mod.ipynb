{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403f5b87",
   "metadata": {},
   "source": [
    "## Brief description of the data set and a summary of its attributes\n",
    "My data set is made up of two columns: English words/sentences and French words/sentences.\n",
    "\n",
    "It contains 175622 rows, of which there wasn’t any null values.\n",
    "\n",
    "I pulled the data set from Kaggle as I needed data containing proper and correct translation of both languages. I am also fluent only in one of the languages, English thus it provided me with a ready made translation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e19cca4",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "- pandas\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "498f79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9021e2c",
   "metadata": {},
   "source": [
    "## Using pandas library to retrieve the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "aebce4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Eng-Fre.csv\"\n",
    "df = pd.read_csv(file, encoding= 'utf-8')\n",
    "df = df.replace('�','',regex = True)\n",
    "#df.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\Eng-Fre2.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9332c7f",
   "metadata": {},
   "source": [
    "## Printing out the first 5 rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "42883f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>?a alors?!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours?!\n",
       "2                    Run!               Courez?!\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             ?a alors?!"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "529d4684",
   "metadata": {},
   "source": [
    "## Checking for any null values\n",
    "Checking for missing values: \n",
    "- **df.isnull()** or **df.isna()** - will return true if null\n",
    "- **df.notnull()** - will return true false if null\n",
    "\n",
    "Handling missing values:\n",
    "1)   Removing rows or columns with missing values: **df.dropna()**\n",
    "2)   Interpolating missing values: **df.interpolate()**\n",
    "3)   Imputing missing values: You can use **df.fillna(value)** to fill missing values with a specific value, or use more advanced techniques like mean, median, or machine learning algorithms for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0b932e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    0\n",
       "French words/sentences     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a20e2116",
   "metadata": {},
   "source": [
    "## Checking for unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2b57fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289032"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faf9a543",
   "metadata": {},
   "source": [
    "## Checking the number of rows\n",
    "Shape function will return a tuple consisting of 2 indices, 1st (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "54508b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6b6987",
   "metadata": {},
   "source": [
    "## Checking for number of records\n",
    "We also could use this to see the number of records in every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a1808bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    175621\n",
       "French words/sentences     175621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2eb088",
   "metadata": {},
   "source": [
    "## Checking for the data types of values within the dataframe\n",
    "We could use **astype(dtype)** to change the data type of records e.g. df.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3f17c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    object\n",
       "French words/sentences     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cae2dcc",
   "metadata": {},
   "source": [
    "## Checking for number of duplicates\n",
    "- Detecting duplicates: **df.duplicated()** to check for duplicate rows.\n",
    "- Removing duplicates: **df.drop_duplicates()** to remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0e68e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1dd6993",
   "metadata": {},
   "source": [
    "## Printing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e0d91cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Stand back!</td>\n",
       "      <td>Reculez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>It's not funny.</td>\n",
       "      <td>Ce n'est pas dr?le !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65263</th>\n",
       "      <td>What time will you leave?</td>\n",
       "      <td>? quelle heure pars-tu??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100309</th>\n",
       "      <td>What's the weather like today?</td>\n",
       "      <td>Quel temps fait-il aujourd'hui??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147869</th>\n",
       "      <td>Medical marijuana is legal in this state.</td>\n",
       "      <td>La marijuana th?rapeutique est l?gale dans cet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          English words/sentences  \\\n",
       "1621                                  Stand back!   \n",
       "8626                              It's not funny.   \n",
       "65263                   What time will you leave?   \n",
       "100309             What's the weather like today?   \n",
       "147869  Medical marijuana is legal in this state.   \n",
       "\n",
       "                                   French words/sentences  \n",
       "1621                                            Reculez !  \n",
       "8626                                 Ce n'est pas dr?le !  \n",
       "65263                            ? quelle heure pars-tu??  \n",
       "100309                   Quel temps fait-il aujourd'hui??  \n",
       "147869  La marijuana th?rapeutique est l?gale dans cet...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8741de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English words/sentences  French words/sentences\n",
       "0                         False                   False\n",
       "1                         False                   False\n",
       "2                         False                   False\n",
       "3                         False                   False\n",
       "4                         False                   False\n",
       "...                         ...                     ...\n",
       "175616                    False                   False\n",
       "175617                    False                   False\n",
       "175618                    False                   False\n",
       "175619                    False                   False\n",
       "175620                    False                   False\n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f71f6f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       Hi.\n",
       "1                                                      Run!\n",
       "2                                                      Run!\n",
       "3                                                      Who?\n",
       "4                                                      Wow!\n",
       "                                ...                        \n",
       "175616    Top-down economics never works, said Obama. \"T...\n",
       "175617    A carbon footprint is the amount of carbon dio...\n",
       "175618    Death is something that we're often discourage...\n",
       "175619    Since there are usually multiple websites on a...\n",
       "175620    If someone who doesn't know your background sa...\n",
       "Name: English words/sentences, Length: 175621, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eng, Fre = df[\"English words/sentences\"], df[\"French words/sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5c855805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Printing out a collection of punctuation marks, ASCII characters\n",
    "print(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2cb05f5",
   "metadata": {},
   "source": [
    "## Removing the Punctuation Marks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31237e78",
   "metadata": {},
   "source": [
    "Initially I did this but then realized that I wasn't really using the fully capabilities of the <span style = \"color:red\">if statement</span>. You notice that I am instead using the else statement to append the letters to my **col** list.\n",
    "\n",
    "    def remove_punc(column):\n",
    "        new_column = []\n",
    "        for word in column:\n",
    "            col = [] \n",
    "            for letter in word:\n",
    "                if letter in string.punctuation:\n",
    "                    letter = letter.replace(letter,'')\n",
    "                else:\n",
    "                    col.append(letter) #list for individual letters now without punctuation mark\n",
    "                new_word = \"\".join(col)\n",
    "            new_column.append(new_word)    \n",
    "        return new_column\n",
    "\n",
    "Instead I used <span style = \"color:blue\">not in</span> which was more effective and cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7558d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(column):\n",
    "    new_column = []\n",
    "    for word in column:\n",
    "        col = []\n",
    "        for letter in word:\n",
    "            if letter not in string.punctuation:\n",
    "                col.append(letter) #list for individual letters now without punctuation mark\n",
    "            new_word = \"\".join(col)\n",
    "        new_column.append(new_word)    \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "54dde395",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Eng = remove_punc(Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3cf3087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Fre = remove_punc(Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0f110edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3670efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Eng = [nltk.word_tokenize(word) for word in No_Punc_Eng]\n",
    "len(tokenized_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b794a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Fre = [nltk.word_tokenize(word) for word in No_Punc_Fre]\n",
    "len(tokenized_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "34d8dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "68ab5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying if that we have English and French Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0aebf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Eng = stopwords.words('english') #179 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a5e76682",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Fre = stopwords.words('french') #157 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "6163df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Eng = []\n",
    "for word in tokenized_Eng:\n",
    "    if word not in stop_Eng:\n",
    "        No_Stop_Eng.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0bfd1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "57d5ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Fre = []\n",
    "for word in tokenized_Fre:\n",
    "    if word not in stop_Fre:\n",
    "        No_Stop_Fre.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "558ced41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5df7dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Fre = []\n",
    "for words in No_Stop_Fre:\n",
    "    for word in words:\n",
    "        lower_Fre.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fba9b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "df2 = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "#df.to_parquet(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.parquet\")\n",
    "df2.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "082cb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 747 ms\n",
      "CPU times: total: 828 ms\n",
      "Wall time: 861 ms\n"
     ]
    }
   ],
   "source": [
    "%time French = pd.read_parquet(\"French.parquet\")\n",
    "%time French2 = pd.read_csv(\"French.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "efc6b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "French = pd.read_parquet(\"French.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "35790dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "French2 = pd.read_csv(\"French.csv\", usecols=lambda col: col != 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "85ea6fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "FrenchPar = dd.read_parquet(\"French.parquet\")\n",
    "FrenchPar.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "05a84bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar = FrenchPar.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f59b26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar.to_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fcb6b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Eng = []\n",
    "for words in No_Stop_Eng:\n",
    "    for word in words:\n",
    "        lower_Eng.append(word.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cf29fa",
   "metadata": {},
   "source": [
    "I will opt for lemmatization and not stemming as I did before:\n",
    "\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Stem--\"))\n",
    "    for word in lower_Eng:\n",
    "        print(\"   {0:25}  {1:25} \".format(word,ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "01724e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all') - Every Package is Up-to-date for my Ellie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7510e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "22ff8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8ae39705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "'''print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Lemma--\"))\n",
    "for word in lower_Fre:\n",
    "    print(\"   {0:25}  {1:25} \".format(word, wnl.lemmatize(word, pos='v')))'''\n",
    "    \n",
    "lemm_Eng = [wnl.lemmatize(word, pos='v') for word in lower_Eng]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04edf951",
   "metadata": {},
   "source": [
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e682391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "Part0 = dd.read_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\\part.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7cd9da93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      French Words\n",
       " 0            salut\n",
       " 1            cours\n",
       " 2           courez\n",
       " 3              qui\n",
       " 4                a\n",
       " ...            ...\n",
       " 56009        elles\n",
       " 56010         sont\n",
       " 56011       toutes\n",
       " 56012          ici\n",
       " 56013          ils\n",
       " \n",
       " [56014 rows x 1 columns],\n",
       "        French Words\n",
       " 56014          sont\n",
       " 56015          tous\n",
       " 56016           moi\n",
       " 56017         elles\n",
       " 56018          sont\n",
       " ...             ...\n",
       " 112024        jtais\n",
       " 112025         trop\n",
       " 112026    ambitieux\n",
       " 112027        jtais\n",
       " 112028         trop\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 112029   ambitieuse\n",
       " 112030        jtais\n",
       " 112031          mal\n",
       " 112032        laise\n",
       " 112033          jai\n",
       " ...             ...\n",
       " 168039           je\n",
       " 168040          lui\n",
       " 168041          dis\n",
       " 168042         quoi\n",
       " 168043        faire\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 168044           je\n",
       " 168045          lui\n",
       " 168046           ai\n",
       " 168047         tout\n",
       " 168048          dit\n",
       " ...             ...\n",
       " 224054           ce\n",
       " 224055         nest\n",
       " 224056         plus\n",
       " 224057           un\n",
       " 224058       enfant\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 224059           ce\n",
       " 224060         nest\n",
       " 224061          pas\n",
       " 224062           un\n",
       " 224063      inconnu\n",
       " ...             ...\n",
       " 280069           en\n",
       " 280070        train\n",
       " 280071           de\n",
       " 280072      djeuner\n",
       " 280073           le\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 280074       miroir\n",
       " 280075          est\n",
       " 280076          trs\n",
       " 280077         sale\n",
       " 280078      largent\n",
       " ...             ...\n",
       " 336084       savoir\n",
       " 336085   voulezvous\n",
       " 336086     vraiment\n",
       " 336087       savoir\n",
       " 336088    tenezvous\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 336089           le\n",
       " 336090       savoir\n",
       " 336091           tu\n",
       " 336092        tiens\n",
       " 336093     vraiment\n",
       " ...             ...\n",
       " 392098           ne\n",
       " 392099          ten\n",
       " 392100     tiendrai\n",
       " 392101          pas\n",
       " 392102      rigueur\n",
       " \n",
       " [56014 rows x 1 columns],\n",
       "        French Words\n",
       " 392103           je\n",
       " 392104           ne\n",
       " 392105         vous\n",
       " 392106           en\n",
       " 392107     tiendrai\n",
       " ...             ...\n",
       " 448113       semble\n",
       " 448114     mcontent\n",
       " 448115          tom\n",
       " 448116            a\n",
       " 448117         lair\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 448118          trs\n",
       " 448119      distant\n",
       " 448120   aujourdhui\n",
       " 448121          tom\n",
       " 448122            a\n",
       " ...             ...\n",
       " 504128           de\n",
       " 504129        temps\n",
       " 504130         vont\n",
       " 504131      prendre\n",
       " 504132          les\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "         French Words\n",
       " 504133    rparations\n",
       " 504134       combien\n",
       " 504135            de\n",
       " 504136         temps\n",
       " 504137  resterezvous\n",
       " ...              ...\n",
       " 560143          cela\n",
       " 560144      personne\n",
       " 560145            ne\n",
       " 560146            me\n",
       " 560147        laisse\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 560148         plus\n",
       " 560149      mamuser\n",
       " 560150     personne\n",
       " 560151           ne\n",
       " 560152          dit\n",
       " ...             ...\n",
       " 616158           de\n",
       " 616159           ne\n",
       " 616160          pas\n",
       " 616161     attendre\n",
       " 616162         plus\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "         French Words\n",
       " 616163     longtemps\n",
       " 616164            il\n",
       " 616165             a\n",
       " 616166       consacr\n",
       " 616167            sa\n",
       " ...              ...\n",
       " 672173      entrions\n",
       " 672174  immdiatement\n",
       " 672175           ils\n",
       " 672176       veulent\n",
       " 672177           que\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 672178         nous\n",
       " 672179     entrions\n",
       " 672180           de\n",
       " 672181        suite\n",
       " 672182        elles\n",
       " ...             ...\n",
       " 728188        plait\n",
       " 728189     veuillez\n",
       " 728190        crire\n",
       " 728191        votre\n",
       " 728192         date\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 728193           de\n",
       " 728194    naissance\n",
       " 728195          ici\n",
       " 728196         cris\n",
       " 728197           ta\n",
       " ...             ...\n",
       " 784202        appel\n",
       " 784203          les\n",
       " 784204     pompiers\n",
       " 784205          mon\n",
       " 784206       voisin\n",
       " \n",
       " [56014 rows x 1 columns],\n",
       "        French Words\n",
       " 784207         sest\n",
       " 784208       plaint\n",
       " 784209           du\n",
       " 784210        bruit\n",
       " 784211           ma\n",
       " ...             ...\n",
       " 840217     toujours\n",
       " 840218          tom\n",
       " 840219      voulait\n",
       " 840220          que\n",
       " 840221        marie\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 840222        garde\n",
       " 840223          ses\n",
       " 840224      enfants\n",
       " 840225          tom\n",
       " 840226      voulait\n",
       " ...             ...\n",
       " 896232         pays\n",
       " 896233           de\n",
       " 896234        quand\n",
       " 896235         date\n",
       " 896236           la\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "        French Words\n",
       " 896237      dernire\n",
       " 896238         fois\n",
       " 896239          que\n",
       " 896240           tu\n",
       " 896241           as\n",
       " ...             ...\n",
       " 952247        vieux\n",
       " 952248         plus\n",
       " 952249           on\n",
       " 952250      devient\n",
       " 952251     distrait\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "         French Words\n",
       " 952252            le\n",
       " 952253          seul\n",
       " 952254         moyen\n",
       " 952255            de\n",
       " 952256        savoir\n",
       " ...              ...\n",
       " 1008262     pourquoi\n",
       " 1008263        distu\n",
       " 1008264          une\n",
       " 1008265        chose\n",
       " 1008266           et\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "         French Words\n",
       " 1008267      ensuite\n",
       " 1008268           tu\n",
       " 1008269            y\n",
       " 1008270          vas\n",
       " 1008271           et\n",
       " ...              ...\n",
       " 1064277           eu\n",
       " 1064278     violente\n",
       " 1064279   divergence\n",
       " 1064280    dopinions\n",
       " 1064281        entre\n",
       " \n",
       " [56015 rows x 1 columns],\n",
       "         French Words\n",
       " 1064282          les\n",
       " 1064283         deux\n",
       " 1064284      leaders\n",
       " 1064285           il\n",
       " 1064286            y\n",
       " ...              ...\n",
       " 1120292     vraiment\n",
       " 1120293        comme\n",
       " 1120294           un\n",
       " 1120295     locuteur\n",
       " 1120296        natif\n",
       " \n",
       " [56015 rows x 1 columns]]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "FreWord = []\n",
    "for word in FrenchPar.to_delayed():\n",
    "    FreWord.append(word.compute())\n",
    "\n",
    "FreWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       French Words \n",
      " 0             salut \n",
      " 1             cours \n",
      " 2            courir \n",
      " 3               qui \n",
      " 4                 avoir \n",
      " ...             ... \n",
      " 56009         lui \n",
      " 56010          être \n",
      " 56011        tout \n",
      " 56012           ici \n",
      " 56013           il \n",
      "\n",
      " [ 56014 row x 1 column ]\n",
      "        French Words \n",
      " 56014           être \n",
      " 56015           tout \n",
      " 56016            moi \n",
      " 56017          lui \n",
      " 56018           être \n",
      " ...              ... \n",
      " 112024         jtais \n",
      " 112025          trop \n",
      " 112026     ambitieux \n",
      " 112027         jtais \n",
      " 112028          trop \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 112029    ambitieux \n",
      " 112030         jtais \n",
      " 112031           mal \n",
      " 112032         laise \n",
      " 112033           jai \n",
      " ...              ... \n",
      " 168039            je \n",
      " 168040           luire \n",
      " 168041           dire \n",
      " 168042          quoi \n",
      " 168043         faire \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 168044            je \n",
      " 168045           luire \n",
      " 168046            avoir \n",
      " 168047          tout \n",
      " 168048           dire \n",
      " ...              ... \n",
      " 224054            ce \n",
      " 224055          nest \n",
      " 224056          plus \n",
      " 224057            un \n",
      " 224058        enfant \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 224059            ce \n",
      " 224060          nest \n",
      " 224061           pas \n",
      " 224062            un \n",
      " 224063       inconnu \n",
      " ...              ... \n",
      " 280069            en \n",
      " 280070         train \n",
      " 280071            de \n",
      " 280072       djeuner \n",
      " 280073            le \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 280074        miroir \n",
      " 280075           être \n",
      " 280076           tr \n",
      " 280077          sale \n",
      " 280078       largent \n",
      " ...              ... \n",
      " 336084        savoir \n",
      " 336085    voulezvou \n",
      " 336086      vraiment \n",
      " 336087        savoir \n",
      " 336088     tenezvous \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 336089            le \n",
      " 336090        savoir \n",
      " 336091            tu \n",
      " 336092         tien \n",
      " 336093      vraiment \n",
      " ...              ... \n",
      " 392098            ne \n",
      " 392099           ten \n",
      " 392100      tenir \n",
      " 392101           pas \n",
      " 392102       rigueur \n",
      "\n",
      " [ 56014 row x 1 column ]\n",
      "        French Words \n",
      " 392103            je \n",
      " 392104            ne \n",
      " 392105          vous \n",
      " 392106            en \n",
      " 392107      tenir \n",
      " ...              ... \n",
      " 448113        sembler \n",
      " 448114      mcontent \n",
      " 448115           tom \n",
      " 448116             avoir \n",
      " 448117          lair \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 448118           tr \n",
      " 448119       dister \n",
      " 448120    aujourdhui \n",
      " 448121           tom \n",
      " 448122             avoir \n",
      " ...              ... \n",
      " 504128            de \n",
      " 504129         temps \n",
      " 504130          aller \n",
      " 504131       prendre \n",
      " 504132           le \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "         French Words \n",
      " 504133     rparatier \n",
      " 504134        combien \n",
      " 504135             de \n",
      " 504136          temps \n",
      " 504137   resterezvous \n",
      " ...               ... \n",
      " 560143           celer \n",
      " 560144       personne \n",
      " 560145             ne \n",
      " 560146             me \n",
      " 560147         laisse \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 560148          plus \n",
      " 560149       mamuser \n",
      " 560150      personne \n",
      " 560151            ne \n",
      " 560152           dire \n",
      " ...              ... \n",
      " 616158            de \n",
      " 616159            ne \n",
      " 616160           pas \n",
      " 616161      attendre \n",
      " 616162          plus \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "         French Words \n",
      " 616163      longtemps \n",
      " 616164             il \n",
      " 616165              avoir \n",
      " 616166        consacr \n",
      " 616167             son \n",
      " ...               ... \n",
      " 672173       entrer \n",
      " 672174   immdiatement \n",
      " 672175            il \n",
      " 672176        vouloir \n",
      " 672177            que \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 672178          nous \n",
      " 672179      entrer \n",
      " 672180            de \n",
      " 672181         suite \n",
      " 672182         lui \n",
      " ...              ... \n",
      " 728188         pler \n",
      " 728189      vouloir \n",
      " 728190         crire \n",
      " 728191         votre \n",
      " 728192          date \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 728193            de \n",
      " 728194     naissance \n",
      " 728195           ici \n",
      " 728196          cri \n",
      " 728197            ton \n",
      " ...              ... \n",
      " 784202         appel \n",
      " 784203           le \n",
      " 784204      pompier \n",
      " 784205           mon \n",
      " 784206        voisin \n",
      "\n",
      " [ 56014 row x 1 column ]\n",
      "        French Words \n",
      " 784207          sest \n",
      " 784208        plaindre \n",
      " 784209            de \n",
      " 784210         bruit \n",
      " 784211            mon \n",
      " ...              ... \n",
      " 840217      toujours \n",
      " 840218           tom \n",
      " 840219       vouloir \n",
      " 840220           que \n",
      " 840221         marier \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 840222         garde \n",
      " 840223           son \n",
      " 840224       enfant \n",
      " 840225           tom \n",
      " 840226       vouloir \n",
      " ...              ... \n",
      " 896232          pays \n",
      " 896233            de \n",
      " 896234         quand \n",
      " 896235          date \n",
      " 896236            le \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "        French Words \n",
      " 896237       dernir \n",
      " 896238          fois \n",
      " 896239           que \n",
      " 896240            tu \n",
      " 896241            as \n",
      " ...              ... \n",
      " 952247         vieux \n",
      " 952248          plus \n",
      " 952249            on \n",
      " 952250       devenir \n",
      " 952251      distraire \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "         French Words \n",
      " 952252             le \n",
      " 952253           seul \n",
      " 952254          moyen \n",
      " 952255             de \n",
      " 952256         savoir \n",
      " ...               ... \n",
      " 1008262      pourquoi \n",
      " 1008263         distu \n",
      " 1008264           un \n",
      " 1008265         chose \n",
      " 1008266            et \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "         French Words \n",
      " 1008267       ensuite \n",
      " 1008268            tu \n",
      " 1008269             y \n",
      " 1008270           aller \n",
      " 1008271            et \n",
      " ...               ... \n",
      " 1064277            avoir \n",
      " 1064278      violent \n",
      " 1064279    divergence \n",
      " 1064280     dopinions \n",
      " 1064281         entrer \n",
      "\n",
      " [ 56015 row x 1 column ]\n",
      "         French Words \n",
      " 1064282           le \n",
      " 1064283          deux \n",
      " 1064284       leader \n",
      " 1064285            il \n",
      " 1064286             y \n",
      " ...               ... \n",
      " 1120292      vraiment \n",
      " 1120293         comme \n",
      " 1120294            un \n",
      " 1120295      locuteur \n",
      " 1120296         natif \n",
      "\n",
      " [ 56015 row x 1 column ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef remove_punc(column):\\n    new_column = []\\n    for word in column:\\n        col = []\\n        for letter in word:\\n            if letter not in string.punctuation:\\n                col.append(letter) #list for individual letters now without punctuation mark\\n            new_word = \"\".join(col)\\n        new_column.append(new_word)    \\n    return new_column\\n\\nremove_punc(FreWord)\\n'"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_col = []\n",
    "for text in FreWord:\n",
    "    doc = nlp(str(text))\n",
    "    col = []\n",
    "    for word in doc:\n",
    "        col.append(word.lemma_)\n",
    "    new_word = \" \".join(col)\n",
    "    new_col.append(new_word)\n",
    "    print(new_word)\n",
    "\n",
    "'''\n",
    "def remove_punc(column):\n",
    "    new_column = []\n",
    "    for word in column:\n",
    "        col = []\n",
    "        for letter in word:\n",
    "            if letter not in string.punctuation:\n",
    "                col.append(letter) #list for individual letters now without punctuation mark\n",
    "            new_word = \"\".join(col)\n",
    "        new_column.append(new_word)    \n",
    "    return new_column\n",
    "\n",
    "remove_punc(FreWord)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b3dd9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French French\n",
      "Words Words\n"
     ]
    }
   ],
   "source": [
    "lemm_Fre = []\n",
    "for text in Part0:\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        print(word,word.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f4ec60",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 70:30 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "791f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng_train, Eng_test, Fre_train, Fre_test = train_test_split(Eng, Fre, test_size= .33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
