{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "403f5b87",
   "metadata": {},
   "source": [
    "## Brief description of the data set and a summary of its attributes\n",
    "My data set is made up of two columns: English words/sentences and French words/sentences.\n",
    "\n",
    "It contains 175622 rows, of which there wasn’t any null values.\n",
    "\n",
    "I pulled the data set from Kaggle as I needed data containing proper and correct translation of both languages. I am also fluent only in one of the languages, English thus it provided me with a ready made translation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e19cca4",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries\n",
    "- pandas\n",
    "- sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498f79bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9021e2c",
   "metadata": {},
   "source": [
    "## Using pandas library to retrieve the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebce4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Eng-Fre.csv\"\n",
    "df = pd.read_csv(file, encoding= 'utf-8')\n",
    "df = df.replace('�','',regex = True)\n",
    "#df.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\Eng-Fre2.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9332c7f",
   "metadata": {},
   "source": [
    "## Printing out the first 5 rows of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42883f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who?</td>\n",
       "      <td>Qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>?a alors?!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  English words/sentences French words/sentences\n",
       "0                     Hi.                 Salut!\n",
       "1                    Run!                Cours?!\n",
       "2                    Run!               Courez?!\n",
       "3                    Who?                  Qui ?\n",
       "4                    Wow!             ?a alors?!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "529d4684",
   "metadata": {},
   "source": [
    "## Checking for any null values\n",
    "Checking for missing values: \n",
    "- **df.isnull()** or **df.isna()** - will return true if null\n",
    "- **df.notnull()** - will return true false if null\n",
    "\n",
    "Handling missing values:\n",
    "1)   Removing rows or columns with missing values: **df.dropna()**\n",
    "2)   Interpolating missing values: **df.interpolate()**\n",
    "3)   Imputing missing values: You can use **df.fillna(value)** to fill missing values with a specific value, or use more advanced techniques like mean, median, or machine learning algorithms for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b932e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    0\n",
       "French words/sentences     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a20e2116",
   "metadata": {},
   "source": [
    "## Checking for unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b57fbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289032"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faf9a543",
   "metadata": {},
   "source": [
    "## Checking the number of rows\n",
    "Shape function will return a tuple consisting of 2 indices, 1st (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54508b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6b6987",
   "metadata": {},
   "source": [
    "## Checking for number of records\n",
    "We also could use this to see the number of records in every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1808bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    175621\n",
       "French words/sentences     175621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb2eb088",
   "metadata": {},
   "source": [
    "## Checking for the data types of values within the dataframe\n",
    "We could use **astype(dtype)** to change the data type of records e.g. df.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f17c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    object\n",
       "French words/sentences     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cae2dcc",
   "metadata": {},
   "source": [
    "## Checking for number of duplicates\n",
    "- Detecting duplicates: **df.duplicated()** to check for duplicate rows.\n",
    "- Removing duplicates: **df.drop_duplicates()** to remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e68e72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1dd6993",
   "metadata": {},
   "source": [
    "## Printing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d91cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>Stand back!</td>\n",
       "      <td>Reculez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8626</th>\n",
       "      <td>It's not funny.</td>\n",
       "      <td>Ce n'est pas dr?le !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65263</th>\n",
       "      <td>What time will you leave?</td>\n",
       "      <td>? quelle heure pars-tu??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100309</th>\n",
       "      <td>What's the weather like today?</td>\n",
       "      <td>Quel temps fait-il aujourd'hui??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147869</th>\n",
       "      <td>Medical marijuana is legal in this state.</td>\n",
       "      <td>La marijuana th?rapeutique est l?gale dans cet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          English words/sentences  \\\n",
       "1621                                  Stand back!   \n",
       "8626                              It's not funny.   \n",
       "65263                   What time will you leave?   \n",
       "100309             What's the weather like today?   \n",
       "147869  Medical marijuana is legal in this state.   \n",
       "\n",
       "                                   French words/sentences  \n",
       "1621                                            Reculez !  \n",
       "8626                                 Ce n'est pas dr?le !  \n",
       "65263                            ? quelle heure pars-tu??  \n",
       "100309                   Quel temps fait-il aujourd'hui??  \n",
       "147869  La marijuana th?rapeutique est l?gale dans cet...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8741de86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175621 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        English words/sentences  French words/sentences\n",
       "0                         False                   False\n",
       "1                         False                   False\n",
       "2                         False                   False\n",
       "3                         False                   False\n",
       "4                         False                   False\n",
       "...                         ...                     ...\n",
       "175616                    False                   False\n",
       "175617                    False                   False\n",
       "175618                    False                   False\n",
       "175619                    False                   False\n",
       "175620                    False                   False\n",
       "\n",
       "[175621 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71f6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng, Fre = df[\"English words/sentences\"], df[\"French words/sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c855805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Printing out a collection of punctuation marks, ASCII characters\n",
    "print(string.punctuation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2cb05f5",
   "metadata": {},
   "source": [
    "## Removing the Punctuation Marks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31237e78",
   "metadata": {},
   "source": [
    "Initially I did this but then realized that I wasn't really using the fully capabilities of the <span style = \"color:red\">if statement</span>. You notice that I am instead using the else statement to append the letters to my **col** list.\n",
    "\n",
    "    def remove_punc(column):\n",
    "        new_column = []\n",
    "        for word in column:\n",
    "            col = [] \n",
    "            for letter in word:\n",
    "                if letter in string.punctuation:\n",
    "                    letter = letter.replace(letter,'')\n",
    "                else:\n",
    "                    col.append(letter) #list for individual letters now without punctuation mark\n",
    "                new_word = \"\".join(col)\n",
    "            new_column.append(new_word)    \n",
    "        return new_column\n",
    "\n",
    "Instead I used <span style = \"color:blue\">not in</span> which was more effective and cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7558d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(column):\n",
    "    new_column = []\n",
    "    for word in column:\n",
    "        col = []\n",
    "        for letter in word:\n",
    "            if letter not in string.punctuation:\n",
    "                col.append(letter) #list for individual letters now without punctuation mark\n",
    "            new_word = \"\".join(col)\n",
    "        new_column.append(new_word)    \n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54dde395",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Eng = remove_punc(Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf3087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Punc_Fre = remove_punc(Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f110edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3670efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Eng = [nltk.word_tokenize(word) for word in No_Punc_Eng]\n",
    "len(tokenized_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b794a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_Fre = [nltk.word_tokenize(word) for word in No_Punc_Fre]\n",
    "len(tokenized_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34d8dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68ab5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying if that we have English and French Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aebf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Eng = stopwords.words('english') #179 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e76682",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_Fre = stopwords.words('french') #157 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6163df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Eng = []\n",
    "for word in tokenized_Eng:\n",
    "    if word not in stop_Eng:\n",
    "        No_Stop_Eng.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bfd1f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57d5ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_Stop_Fre = []\n",
    "for word in tokenized_Fre:\n",
    "    if word not in stop_Fre:\n",
    "        No_Stop_Fre.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "558ced41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175621"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(No_Stop_Fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5df7dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Fre = []\n",
    "for words in No_Stop_Fre:\n",
    "    for word in words:\n",
    "        lower_Fre.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fba9b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "df2 = pd.DataFrame(lower_Fre,columns= [\"French Words\"])\n",
    "#df.to_parquet(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.parquet\")\n",
    "df2.to_csv(\"C:\\\\Users\\\\Bildad Otieno\\\\Documents\\\\Billy_Repo\\\\Translation_Mod\\\\French.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "082cb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 454 ms\n",
      "CPU times: total: 703 ms\n",
      "Wall time: 791 ms\n"
     ]
    }
   ],
   "source": [
    "%time French = pd.read_parquet(\"French.parquet\")\n",
    "%time French2 = pd.read_csv(\"French.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "efc6b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "French = pd.read_parquet(\"French.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35790dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "French2 = pd.read_csv(\"French.csv\", usecols=lambda col: col != 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "85ea6fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "FrenchPar = dd.read_parquet(\"French.parquet\")\n",
    "FrenchPar.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05a84bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar = FrenchPar.repartition(npartitions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f59b26eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FrenchPar.to_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb6b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_Eng = []\n",
    "for words in No_Stop_Eng:\n",
    "    for word in words:\n",
    "        lower_Eng.append(word.lower())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9cf29fa",
   "metadata": {},
   "source": [
    "I will opt for lemmatization and not stemming as I did before:\n",
    "\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Stem--\"))\n",
    "    for word in lower_Eng:\n",
    "        print(\"   {0:25}  {1:25} \".format(word,ps.stem(word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01724e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all') - Every Package is Up-to-date for my Ellie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7510e726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22ff8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae39705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Bildad\n",
      "[nltk_data]     Otieno/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "'''print(\" {0:25}  {1:25} \".format(\"--Word(s)--\",\"--Lemma--\"))\n",
    "for word in lower_Fre:\n",
    "    print(\"   {0:25}  {1:25} \".format(word, wnl.lemmatize(word, pos='v')))'''\n",
    "    \n",
    "lemm_Eng = [wnl.lemmatize(word, pos='v') for word in lower_Eng]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04edf951",
   "metadata": {},
   "source": [
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e682391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "Part0 = dd.read_parquet(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\French\\part.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7cd9da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      French Words\n",
      "0            salut\n",
      "1            cours\n",
      "2           courez\n",
      "3              qui\n",
      "4                a\n",
      "...            ...\n",
      "56009        elles\n",
      "56010         sont\n",
      "56011       toutes\n",
      "56012          ici\n",
      "56013          ils\n",
      "\n",
      "[56014 rows x 1 columns]\n",
      "       French Words\n",
      "56014          sont\n",
      "56015          tous\n",
      "56016           moi\n",
      "56017         elles\n",
      "56018          sont\n",
      "...             ...\n",
      "112024        jtais\n",
      "112025         trop\n",
      "112026    ambitieux\n",
      "112027        jtais\n",
      "112028         trop\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "112029   ambitieuse\n",
      "112030        jtais\n",
      "112031          mal\n",
      "112032        laise\n",
      "112033          jai\n",
      "...             ...\n",
      "168039           je\n",
      "168040          lui\n",
      "168041          dis\n",
      "168042         quoi\n",
      "168043        faire\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "168044           je\n",
      "168045          lui\n",
      "168046           ai\n",
      "168047         tout\n",
      "168048          dit\n",
      "...             ...\n",
      "224054           ce\n",
      "224055         nest\n",
      "224056         plus\n",
      "224057           un\n",
      "224058       enfant\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "224059           ce\n",
      "224060         nest\n",
      "224061          pas\n",
      "224062           un\n",
      "224063      inconnu\n",
      "...             ...\n",
      "280069           en\n",
      "280070        train\n",
      "280071           de\n",
      "280072      djeuner\n",
      "280073           le\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "280074       miroir\n",
      "280075          est\n",
      "280076          trs\n",
      "280077         sale\n",
      "280078      largent\n",
      "...             ...\n",
      "336084       savoir\n",
      "336085   voulezvous\n",
      "336086     vraiment\n",
      "336087       savoir\n",
      "336088    tenezvous\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "336089           le\n",
      "336090       savoir\n",
      "336091           tu\n",
      "336092        tiens\n",
      "336093     vraiment\n",
      "...             ...\n",
      "392098           ne\n",
      "392099          ten\n",
      "392100     tiendrai\n",
      "392101          pas\n",
      "392102      rigueur\n",
      "\n",
      "[56014 rows x 1 columns]\n",
      "       French Words\n",
      "392103           je\n",
      "392104           ne\n",
      "392105         vous\n",
      "392106           en\n",
      "392107     tiendrai\n",
      "...             ...\n",
      "448113       semble\n",
      "448114     mcontent\n",
      "448115          tom\n",
      "448116            a\n",
      "448117         lair\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "448118          trs\n",
      "448119      distant\n",
      "448120   aujourdhui\n",
      "448121          tom\n",
      "448122            a\n",
      "...             ...\n",
      "504128           de\n",
      "504129        temps\n",
      "504130         vont\n",
      "504131      prendre\n",
      "504132          les\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "        French Words\n",
      "504133    rparations\n",
      "504134       combien\n",
      "504135            de\n",
      "504136         temps\n",
      "504137  resterezvous\n",
      "...              ...\n",
      "560143          cela\n",
      "560144      personne\n",
      "560145            ne\n",
      "560146            me\n",
      "560147        laisse\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "560148         plus\n",
      "560149      mamuser\n",
      "560150     personne\n",
      "560151           ne\n",
      "560152          dit\n",
      "...             ...\n",
      "616158           de\n",
      "616159           ne\n",
      "616160          pas\n",
      "616161     attendre\n",
      "616162         plus\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "        French Words\n",
      "616163     longtemps\n",
      "616164            il\n",
      "616165             a\n",
      "616166       consacr\n",
      "616167            sa\n",
      "...              ...\n",
      "672173      entrions\n",
      "672174  immdiatement\n",
      "672175           ils\n",
      "672176       veulent\n",
      "672177           que\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "672178         nous\n",
      "672179     entrions\n",
      "672180           de\n",
      "672181        suite\n",
      "672182        elles\n",
      "...             ...\n",
      "728188        plait\n",
      "728189     veuillez\n",
      "728190        crire\n",
      "728191        votre\n",
      "728192         date\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "728193           de\n",
      "728194    naissance\n",
      "728195          ici\n",
      "728196         cris\n",
      "728197           ta\n",
      "...             ...\n",
      "784202        appel\n",
      "784203          les\n",
      "784204     pompiers\n",
      "784205          mon\n",
      "784206       voisin\n",
      "\n",
      "[56014 rows x 1 columns]\n",
      "       French Words\n",
      "784207         sest\n",
      "784208       plaint\n",
      "784209           du\n",
      "784210        bruit\n",
      "784211           ma\n",
      "...             ...\n",
      "840217     toujours\n",
      "840218          tom\n",
      "840219      voulait\n",
      "840220          que\n",
      "840221        marie\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "840222        garde\n",
      "840223          ses\n",
      "840224      enfants\n",
      "840225          tom\n",
      "840226      voulait\n",
      "...             ...\n",
      "896232         pays\n",
      "896233           de\n",
      "896234        quand\n",
      "896235         date\n",
      "896236           la\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "       French Words\n",
      "896237      dernire\n",
      "896238         fois\n",
      "896239          que\n",
      "896240           tu\n",
      "896241           as\n",
      "...             ...\n",
      "952247        vieux\n",
      "952248         plus\n",
      "952249           on\n",
      "952250      devient\n",
      "952251     distrait\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "        French Words\n",
      "952252            le\n",
      "952253          seul\n",
      "952254         moyen\n",
      "952255            de\n",
      "952256        savoir\n",
      "...              ...\n",
      "1008262     pourquoi\n",
      "1008263        distu\n",
      "1008264          une\n",
      "1008265        chose\n",
      "1008266           et\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "        French Words\n",
      "1008267      ensuite\n",
      "1008268           tu\n",
      "1008269            y\n",
      "1008270          vas\n",
      "1008271           et\n",
      "...              ...\n",
      "1064277           eu\n",
      "1064278     violente\n",
      "1064279   divergence\n",
      "1064280    dopinions\n",
      "1064281        entre\n",
      "\n",
      "[56015 rows x 1 columns]\n",
      "        French Words\n",
      "1064282          les\n",
      "1064283         deux\n",
      "1064284      leaders\n",
      "1064285           il\n",
      "1064286            y\n",
      "...              ...\n",
      "1120292     vraiment\n",
      "1120293        comme\n",
      "1120294           un\n",
      "1120295     locuteur\n",
      "1120296        natif\n",
      "\n",
      "[56015 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "for word in FrenchPar.to_delayed():\n",
    "    partition = word.compute()\n",
    "    print(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3dd9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French French\n",
      "Words Words\n"
     ]
    }
   ],
   "source": [
    "lemm_Fre = []\n",
    "for text in Part0:\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        print(word,word.lemma_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8f4ec60",
   "metadata": {},
   "source": [
    "## Splitting Dataset into 70:30 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "791f51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eng_train, Eng_test, Fre_train, Fre_test = train_test_split(Eng, Fre, test_size= .33, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
