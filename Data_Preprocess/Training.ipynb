{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Data_Preprocess\\lemmatized_French\\French_lemmatized.csv\", encoding='ISO-8859-1')\n",
    "df.index = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>courir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>avoir alors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175616</th>\n",
       "      <td>lconomi en partir de haut vers le bas avoir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175617</th>\n",
       "      <td>un empreinte carbone être le somme de pollutio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175618</th>\n",
       "      <td>le mort être un chose quon nous dcourage souve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175619</th>\n",
       "      <td>puisquil y avoir de multiple site web sur chaq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175620</th>\n",
       "      <td>si quelquun qui ne connat pas votre antcdent d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175620 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             French Words\n",
       "1                                                   salut\n",
       "2                                                   cours\n",
       "3                                                  courir\n",
       "4                                                     qui\n",
       "5                                             avoir alors\n",
       "...                                                   ...\n",
       "175616    lconomi en partir de haut vers le bas avoir ...\n",
       "175617  un empreinte carbone être le somme de pollutio...\n",
       "175618  le mort être un chose quon nous dcourage souve...\n",
       "175619  puisquil y avoir de multiple site web sur chaq...\n",
       "175620  si quelquun qui ne connat pas votre antcdent d...\n",
       "\n",
       "[175620 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Data_Preprocess\\lemmatized_English\\English_lemmatized.csv\")\n",
    "df2.index = df.index + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         False\n",
       "2         False\n",
       "3          True\n",
       "4         False\n",
       "5         False\n",
       "          ...  \n",
       "175616    False\n",
       "175617    False\n",
       "175618    False\n",
       "175619    False\n",
       "175620    False\n",
       "Length: 175620, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use a raw string (r) to avoid 'unicodeescape' error\n",
    "file_path = r'C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Data_Preprocess\\lemmatized_French\\French_lemmatized.csv'\n",
    "\n",
    "# Open the CSV file with the correct encoding and handle decoding errors\n",
    "with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    # Pass the file handle to pd.read_csv()\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "# Now you can work with the DataFrame 'df' as usual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df,df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(r\"C:\\Users\\Bildad Otieno\\Documents\\Billy_Repo\\Translation_Mod\\Data_Preprocess\\Preprocessed_Dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf_train, newdf_test = train_test_split(newdf, test_size= .2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
